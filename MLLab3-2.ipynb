{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harshitha020505/MLLab1/blob/main/MLLab3-2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2XgHL3DoigKe"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv(\"titanic_train.csv\")\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4bQFkZxsWHzj"
      },
      "outputs": [],
      "source": [
        "df['Age'].fillna(df['Age'].median(), inplace=True)\n",
        "df['Fare'].fillna(df['Fare'].mean(), inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FqbsOhimoy5H"
      },
      "outputs": [],
      "source": [
        "df.ffill()\n",
        "print(df.isnull().sum)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5mw8lAKDkbGW"
      },
      "outputs": [],
      "source": [
        "#CONSTANT FEATURES\n",
        "from sklearn.model_selection import train_test_split\n",
        "[col for col in df.columns if df[col].isnull().sum()>0]\n",
        "X=df.drop('Survived',axis=1)\n",
        "X=pd.get_dummies(X,drop_first=True)\n",
        "y=df['Survived']\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)\n",
        "constant_features=[features for features in X_train.columns if X_train[features].std()==0]\n",
        "print(len(constant_features))\n",
        "X_train.drop(columns=constant_features, inplace=True)\n",
        "X_test.drop(columns=constant_features, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SrtWeebZUC_T"
      },
      "outputs": [],
      "source": [
        "#quasi-constant features\n",
        "X = df.drop('Survived', axis=1)\n",
        "y = df['Survived']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
        "quasi_constant_features=[]\n",
        "for feature in X_train.columns:\n",
        "  predominant=(X_train[feature].value_counts()/float(len(X_train))).sort_values(ascending=False).values[0]\n",
        "  if(predominant>0.99):\n",
        "    quasi_constant_features.append(feature)\n",
        "print(len(quasi_constant_features))\n",
        "print(quasi_constant_features)\n",
        "X_train.drop(columns=quasi_constant_features, inplace=True)\n",
        "X_test.drop(columns=quasi_constant_features, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ASujxXNOVXTm"
      },
      "outputs": [],
      "source": [
        "#duplicated features\n",
        "dup=[]\n",
        "for i in range(0,len(X_train.columns)):\n",
        "  col1=X_train.columns[i]\n",
        "  for col2 in X_train.columns[i+1:]:\n",
        "    if(X_train[col1].equals(X_train[col2])):\n",
        "      dup.append(col2)\n",
        "print(len(dup))\n",
        "print(dup)\n",
        "X_train.drop(columns=dup, inplace=True)\n",
        "X_test.drop(columns=dup, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JesAq2NEVftV"
      },
      "outputs": [],
      "source": [
        "# Correlation\n",
        "grouped_feature_ls = []\n",
        "correlated_groups = []\n",
        "\n",
        "def correlation(dataset, threshold):\n",
        "    col_corr = set()\n",
        "    numeric_df = dataset.select_dtypes(include=['number'])  # Only numeric columns\n",
        "    col_matrix = numeric_df.corr()\n",
        "    for i in range(len(col_matrix.columns)):\n",
        "        for j in range(i):\n",
        "            if abs(col_matrix.iloc[i, j]\n",
        "                   ) > threshold:\n",
        "                colname = col_matrix.columns[i]\n",
        "                col_corr.add(colname)\n",
        "    return col_corr\n",
        "\n",
        "corr_features = correlation(df, 0.9)\n",
        "corr_final = set(corr_features)\n",
        "print(len(corr_final))\n",
        "X_train.drop(columns=corr_final, inplace=True)\n",
        "X_test.drop(columns=corr_final, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iv6FnaVRVlHQ"
      },
      "outputs": [],
      "source": [
        "#Mutual Information\n",
        "from sklearn.feature_selection import mutual_info_classif, SelectKBest\n",
        "import pandas as pd\n",
        "\n",
        "X = df.drop('Survived', axis=1)\n",
        "X = pd.get_dummies(X, drop_first=True)\n",
        "y = df['Survived']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
        "\n",
        "mi_scores = mutual_info_classif(X.fillna(0), y)\n",
        "mi_scores = pd.Series(mi_scores, index=X.columns)\n",
        "mi_scores = mi_scores.sort_values(ascending=False)\n",
        "print(\"Mutual Information Scores\", mi_scores)\n",
        "\n",
        "X_train_encoded = pd.get_dummies(X_train, drop_first=True).fillna(0)\n",
        "sel_ = SelectKBest(mutual_info_classif, k=10).fit(X_train_encoded, y_train)\n",
        "\n",
        "top_features = X_train_encoded.columns[sel_.get_support()]\n",
        "print(\"\\nTop 10 Features:\\n\", top_features)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cfuKoh0vYNQu"
      },
      "outputs": [],
      "source": [
        "#CHI SQUARE TEst\n",
        "from scipy.stats import chi2_contingency\n",
        "result=[]\n",
        "for feature in X_train.columns:\n",
        "  crosstab=pd.crosstab(X_train[feature],df['Survived'])\n",
        "  chi2_stat,p_val,dof,expected=chi2_contingency(crosstab)\n",
        "  if p_val<0.05:\n",
        "    result.append(feature)\n",
        "print(result)\n",
        "X_train.drop(columns=feature, inplace=True)\n",
        "X_test.drop(columns=feature, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yv1bjftbzVgj"
      },
      "outputs": [],
      "source": [
        "#Anova\n",
        "from sklearn.feature_selection import f_classif, SelectKBest\n",
        "anova_selector = SelectKBest(score_func=f_classif, k=10)\n",
        "anova_selector.fit(X_train, y_train)\n",
        "\n",
        "top_features = X_train.columns[anova_selector.get_support()]\n",
        "print(top_features)\n",
        "\n",
        "anova_scores = pd.Series(anova_selector.scores_, index=X_train.columns)\n",
        "anova_scores = anova_scores.sort_values(ascending=False)\n",
        "print(anova_scores.head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GjitF53SpXPt"
      },
      "outputs": [],
      "source": [
        "#forward Selection\n",
        "import numpy as np\n",
        "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "sfs1=SFS(RandomForestClassifier(n_jobs=4),k_features=5,forward=True,scoring='roc_auc' or 'accuracy',cv=3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5cMFTBKhua9R"
      },
      "outputs": [],
      "source": [
        "sfs1=sfs1.fit(X_train,y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7WSO0bcFyhxA"
      },
      "outputs": [],
      "source": [
        "print(sfs1.k_score_)\n",
        "print(sfs1.k_feature_idx_)\n",
        "print(sfs1.k_feature_names_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "76Smh88ApXLE"
      },
      "outputs": [],
      "source": [
        "#Backward Selection\n",
        "import numpy as np\n",
        "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "sfs1=SFS(RandomForestClassifier(n_jobs=4),k_features=5,forward=False,scoring='roc_auc' or 'accuracy',cv=3)\n",
        "sfs1=sfs1.fit(np.array(X_train),y_train)\n",
        "print(sfs1.k_score_)\n",
        "print(sfs1.k_feature_idx_)\n",
        "print(sfs1.k_feature_names_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q1SA6CskxFgh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kdUi-edZpXG8"
      },
      "outputs": [],
      "source": [
        "#exhastive feature selection\n",
        "from mlxtend.feature_selection import ExhaustiveFeatureSelector as EFS\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "efs1=EFS(RandomForestClassifier(n_jobs=4),min_features=1,max_features=4,scoring='accuracy',cv=3)\n",
        "efs1=efs1.fit(X_train,y_train)\n",
        "print(efs1.best_idx_)\n",
        "print(efs1.best_score_)\n",
        "print(efs1.best_feature_names_)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Principal Component Analysis And Linear Discriminant Analysis\n",
        "import pandas as pd\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "\n",
        "\n",
        "X[\"Sex\"] = LabelEncoder().fit_transform(X[\"Sex\"])\n",
        "X[\"Embarked\"] = LabelEncoder().fit_transform(X[\"Embarked\"])\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "pca = PCA(n_components=2)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "lda = LDA(n_components=1)\n",
        "X_lda = lda.fit_transform(X_scaled, y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Explained variance ratio by PCA:\", pca.explained_variance_ratio_)\n",
        "print(\"Shape after PCA:\", X_pca.shape)\n",
        "print(\"Shape after LDA:\", X_lda.shape)\n"
      ],
      "metadata": {
        "id": "7L52FBPNRcjh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "02Fwv40OpXC8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DgI7uXPhYZKu"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df1=pd.read_csv(\"Santander Customer Satisfaction_train.csv\")\n",
        "print(df1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0bBFg3JcYp-_"
      },
      "outputs": [],
      "source": [
        "#CONSTANT FEATURES\n",
        "from sklearn.model_selection import train_test_split\n",
        "[col for col in df1.columns if df1[col].isnull().sum()>0]\n",
        "X=df1.drop('TARGET',axis=1)\n",
        "X=pd.get_dummies(X,drop_first=True)\n",
        "y=df1['TARGET']\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)\n",
        "constant_features=[features for features in X_train.columns if X_train[features].std()==0]\n",
        "print(len(constant_features))\n",
        "X_train.drop(columns=constant_features, inplace=True)\n",
        "X_test.drop(columns=constant_features, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u5r8CXTeZO0O"
      },
      "outputs": [],
      "source": [
        "#quasi-constant features\n",
        "X = df1.drop('TARGET', axis=1)\n",
        "y = df1['TARGET']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
        "quasi_constant_features=[]\n",
        "for feature in X_train.columns:\n",
        "  predominant=(X_train[feature].value_counts()/float(len(X_train))).sort_values(ascending=False).values[0]\n",
        "  if(predominant>0.99):\n",
        "    quasi_constant_features.append(feature)\n",
        "print(len(quasi_constant_features))\n",
        "print(quasi_constant_features)\n",
        "X_train.drop(columns=quasi_constant_features, inplace=True)\n",
        "X_test.drop(columns=quasi_constant_features, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A3zLWaTSZbr8"
      },
      "outputs": [],
      "source": [
        "#duplicated features\n",
        "dup=[]\n",
        "for i in range(0,len(X_train.columns)):\n",
        "  col1=X_train.columns[i]\n",
        "  for col2 in X_train.columns[i+1:]:\n",
        "    if(X_train[col1].equals(X_train[col2])):\n",
        "      dup.append(col2)\n",
        "print(len(dup))\n",
        "print(dup)\n",
        "X_train.drop(columns=dup, inplace=True)\n",
        "X_test.drop(columns=dup, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WkVEi-uTZrGa"
      },
      "outputs": [],
      "source": [
        "# Correlation\n",
        "grouped_feature_ls = []\n",
        "correlated_groups = []\n",
        "\n",
        "def correlation(dataset, threshold):\n",
        "    col_corr = set()\n",
        "    numeric_df = dataset.select_dtypes(include=['number'])\n",
        "    col_matrix = numeric_df.corr()\n",
        "    for i in range(len(col_matrix.columns)):\n",
        "        for j in range(i):\n",
        "            if abs(col_matrix.iloc[i, j]) > threshold:\n",
        "                colname = col_matrix.columns[i]\n",
        "                col_corr.add(colname)\n",
        "    return col_corr\n",
        "\n",
        "corr_features = correlation(df1, 0.9)\n",
        "corr_final = set(corr_features)\n",
        "print(len(corr_final))\n",
        "\n",
        "X_train.drop(columns=corr_final, inplace=True, errors='ignore')\n",
        "X_test.drop(columns=corr_final, inplace=True, errors='ignore')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OT82VGXJZ_bM"
      },
      "outputs": [],
      "source": [
        "#Mutual Information\n",
        "from sklearn.feature_selection import mutual_info_classif, SelectKBest\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "df1 = df1.dropna(subset=['TARGET'])\n",
        "X = df1.drop('TARGET', axis=1)\n",
        "X = pd.get_dummies(X, drop_first=True)\n",
        "y = df1['TARGET']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
        "\n",
        "mi_scores = mutual_info_classif(X.fillna(0), y)\n",
        "mi_scores = pd.Series(mi_scores, index=X.columns)\n",
        "mi_scores = mi_scores.sort_values(ascending=False)\n",
        "print(\"Mutual Information Scores:\\n\", mi_scores)\n",
        "\n",
        "X_train_encoded = pd.get_dummies(X_train, drop_first=True).fillna(0)\n",
        "sel_ = SelectKBest(mutual_info_classif, k=10).fit(X_train_encoded, y_train)\n",
        "\n",
        "top_features = X_train_encoded.columns[sel_.get_support()]\n",
        "print(\"\\nTop 10 Features:\\n\", top_features)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Og9Nn7xQcnA2"
      },
      "outputs": [],
      "source": [
        "#Anova\n",
        "from sklearn.feature_selection import f_classif, SelectKBest\n",
        "anova_selector = SelectKBest(score_func=f_classif, k=10)\n",
        "anova_selector.fit(X_train, y_train)\n",
        "\n",
        "top_features = X_train.columns[anova_selector.get_support()]\n",
        "print(top_features)\n",
        "\n",
        "anova_scores = pd.Series(anova_selector.scores_, index=X_train.columns)\n",
        "anova_scores = anova_scores.sort_values(ascending=False)\n",
        "print(anova_scores.head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dhuSMdLtF575"
      },
      "outputs": [],
      "source": [
        "#forward Selection\n",
        "import numpy as np\n",
        "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "sfs1=SFS(RandomForestClassifier(n_jobs=4),k_features=5,forward=True,scoring='roc_auc' or 'accuracy',cv=3)\n",
        "sfs1=sfs1.fit(X_train,y_train)\n",
        "print(sfs1.k_score_)\n",
        "print(sfs1.k_feature_idx_)\n",
        "print(sfs1.k_feature_names_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f_V6fvdDG7wv"
      },
      "outputs": [],
      "source": [
        "#Backward Selection\n",
        "import numpy as np\n",
        "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "sfs1=SFS(RandomForestClassifier(n_jobs=4),k_features=5,forward=False,scoring='roc_auc' or 'accuracy',cv=3)\n",
        "sfs1=sfs1.fit(np.array(X_train),y_train)\n",
        "print(sfs1.k_score_)\n",
        "print(sfs1.k_feature_idx_)\n",
        "print(sfs1.k_feature_names_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pH_alo3OHHOd"
      },
      "outputs": [],
      "source": [
        "#exhastive feature selection\n",
        "from mlxtend.feature_selection import ExhaustiveFeatureSelector as EFS\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "efs1=EFS(RandomForestClassifier(n_jobs=4),min_features=1,max_features=4,scoring='accuracy',cv=3)\n",
        "efs1=efs1.fit(X_train,y_train)\n",
        "print(efs1.best_idx_)\n",
        "print(efs1.best_score_)\n",
        "print(efs1.best_feature_names_)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Principal Component Analysis And Linear Discriminant Analysis\n",
        "import pandas as pd\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "for col in X.select_dtypes(include=[\"object\"]).columns:\n",
        "    X[col] = LabelEncoder().fit_transform(X[col])\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "pca = PCA(n_components=2)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "lda = LDA(n_components=1)\n",
        "X_lda = lda.fit_transform(X_scaled, y)\n",
        "\n",
        "print(\"Explained variance ratio (PCA):\", pca.explained_variance_ratio_)\n",
        "print(\"Shape after PCA:\", X_pca.shape)\n",
        "print(\"Shape after LDA:\", X_lda.shape)\n"
      ],
      "metadata": {
        "id": "sZ6ussxVWWNL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NL2aice0coNd",
        "outputId": "87bf981b-dcaf-4ca3-e5ee-081dfcf9b122"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        Id  MSSubClass MSZoning  ...  SaleType  SaleCondition SalePrice\n",
            "0        1          60       RL  ...        WD         Normal    208500\n",
            "1        2          20       RL  ...        WD         Normal    181500\n",
            "2        3          60       RL  ...        WD         Normal    223500\n",
            "3        4          70       RL  ...        WD        Abnorml    140000\n",
            "4        5          60       RL  ...        WD         Normal    250000\n",
            "...    ...         ...      ...  ...       ...            ...       ...\n",
            "1455  1456          60       RL  ...        WD         Normal    175000\n",
            "1456  1457          20       RL  ...        WD         Normal    210000\n",
            "1457  1458          70       RL  ...        WD         Normal    266500\n",
            "1458  1459          20       RL  ...        WD         Normal    142125\n",
            "1459  1460          20       RL  ...        WD         Normal    147500\n",
            "\n",
            "[1460 rows x 81 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df3=pd.read_csv(\"house_price_train.csv\")\n",
        "print(df3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hY5s9ey_dXHQ",
        "outputId": "d998884d-1012-4da1-9a64-b30cf99ad5c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n"
          ]
        }
      ],
      "source": [
        "#CONSTANT FEATURES\n",
        "from sklearn.model_selection import train_test_split\n",
        "[col for col in df3.columns if df3[col].isnull().sum()>0]\n",
        "X=df3.drop('SalePrice',axis=1)\n",
        "X=pd.get_dummies(X,drop_first=True)\n",
        "y=df3['SalePrice']\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)\n",
        "constant_features=[features for features in X_train.columns if X_train[features].std()==0]\n",
        "print(len(constant_features))\n",
        "X_train.drop(columns=constant_features, inplace=True)\n",
        "X_test.drop(columns=constant_features, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h69veJOWdcIu",
        "outputId": "3bba8abb-e1ac-4a78-b87c-e5d10292cff6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n",
            "['Street', 'Utilities', 'Condition2', 'PoolArea']\n"
          ]
        }
      ],
      "source": [
        "#quasi-constant features\n",
        "X = df3.drop('SalePrice', axis=1)\n",
        "y = df3['SalePrice']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
        "quasi_constant_features=[]\n",
        "for feature in X_train.columns:\n",
        "  predominant=(X_train[feature].value_counts()/float(len(X_train))).sort_values(ascending=False).values[0]\n",
        "  if(predominant>0.99):\n",
        "    quasi_constant_features.append(feature)\n",
        "print(len(quasi_constant_features))\n",
        "print(quasi_constant_features)\n",
        "X_train.drop(columns=quasi_constant_features, inplace=True)\n",
        "X_test.drop(columns=quasi_constant_features, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2KmCJCcdf5g",
        "outputId": "0273389c-08d3-41a0-ace2-6a80d6df656f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "[]\n"
          ]
        }
      ],
      "source": [
        "#duplicated features\n",
        "dup=[]\n",
        "for i in range(0,len(X_train.columns)):\n",
        "  col1=X_train.columns[i]\n",
        "  for col2 in X_train.columns[i+1:]:\n",
        "    if(X_train[col1].equals(X_train[col2])):\n",
        "      dup.append(col2)\n",
        "print(len(dup))\n",
        "print(dup)\n",
        "X_train.drop(columns=dup, inplace=True)\n",
        "X_test.drop(columns=dup, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6Z4zH_vdisu",
        "outputId": "ddfe4ae6-74f4-4fcc-95e7-bb80670020e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ],
      "source": [
        "# Correlation\n",
        "grouped_feature_ls = []\n",
        "correlated_groups = []\n",
        "\n",
        "def correlation(dataset, threshold):\n",
        "    col_corr = set()\n",
        "    numeric_df = dataset.select_dtypes(include=['number'])\n",
        "    col_matrix = numeric_df.corr()\n",
        "    for i in range(len(col_matrix.columns)):\n",
        "        for j in range(i):\n",
        "            if abs(col_matrix.iloc[i, j]) > threshold:\n",
        "                colname = col_matrix.columns[i]\n",
        "                col_corr.add(colname)\n",
        "    return col_corr\n",
        "\n",
        "corr_features = correlation(df3, 0.9)\n",
        "corr_final = set(corr_features)\n",
        "print(len(corr_final))\n",
        "\n",
        "X_train.drop(columns=corr_final, inplace=True, errors='ignore')\n",
        "X_test.drop(columns=corr_final, inplace=True, errors='ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftDdV-6FfV00",
        "outputId": "618f87c6-6fd7-40d0-cb48-b52768a14c63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mutual Information Scores:\n",
            " Street_Pave              3.232847\n",
            "RoofMatl_CompShg         3.178248\n",
            "Condition2_Norm          3.039581\n",
            "CentralAir_Y             2.950983\n",
            "Heating_GasA             2.928889\n",
            "                           ...   \n",
            "SaleType_CWD             0.000000\n",
            "MiscFeature_Othr         0.000000\n",
            "SaleType_Oth             0.000000\n",
            "SaleCondition_AdjLand    0.000000\n",
            "SaleCondition_Family     0.000000\n",
            "Length: 245, dtype: float64\n",
            "\n",
            "Top 10 Features:\n",
            " Index(['KitchenAbvGr', 'Street_Pave', 'Condition2_Norm', 'RoofMatl_CompShg',\n",
            "       'Heating_GasA', 'CentralAir_Y', 'Electrical_SBrkr', 'Functional_Typ',\n",
            "       'GarageQual_TA', 'SaleType_WD'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "#Mutual Information\n",
        "from sklearn.feature_selection import mutual_info_classif, SelectKBest\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "df3 = df3.dropna(subset=['SalePrice'])\n",
        "X = df3.drop('SalePrice', axis=1)\n",
        "X = pd.get_dummies(X, drop_first=True)\n",
        "y = df3['SalePrice']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
        "\n",
        "mi_scores = mutual_info_classif(X.fillna(0), y)\n",
        "mi_scores = pd.Series(mi_scores, index=X.columns)\n",
        "mi_scores = mi_scores.sort_values(ascending=False)\n",
        "print(\"Mutual Information Scores:\\n\", mi_scores)\n",
        "\n",
        "X_train_encoded = pd.get_dummies(X_train, drop_first=True).fillna(0)\n",
        "sel_ = SelectKBest(mutual_info_classif, k=10).fit(X_train_encoded, y_train)\n",
        "\n",
        "top_features = X_train_encoded.columns[sel_.get_support()]\n",
        "print(\"\\nTop 10 Features:\\n\", top_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nk8TYx_0dm4K",
        "outputId": "5ff575b3-7401-4da8-bc8b-78839a57cdb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top 10 Features (f_regression):\n",
            " Index(['OverallQual', 'TotalBsmtSF', '1stFlrSF', 'GrLivArea', 'FullBath',\n",
            "       'TotRmsAbvGrd', 'GarageCars', 'GarageArea', 'ExterQual_TA',\n",
            "       'KitchenQual_TA'],\n",
            "      dtype='object')\n",
            "\n",
            "Regression Feature Scores:\n",
            " OverallQual       1628.570495\n",
            "GrLivArea         1131.879650\n",
            "GarageCars         758.024880\n",
            "GarageArea         727.175552\n",
            "TotalBsmtSF        654.341155\n",
            "1stFlrSF           605.576313\n",
            "ExterQual_TA       499.122655\n",
            "FullBath           497.954582\n",
            "TotRmsAbvGrd       431.845019\n",
            "KitchenQual_TA     376.161106\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "#Anova f_regression\n",
        "from sklearn.feature_selection import f_regression, SelectKBest\n",
        "import pandas as pd\n",
        "\n",
        "X_train = X_train.fillna(X_train.mean())\n",
        "X_test = X_test.fillna(X_test.mean())\n",
        "\n",
        "selector = SelectKBest(score_func=f_regression, k=10)\n",
        "selector.fit(X_train, y_train)\n",
        "\n",
        "top_features = X_train.columns[selector.get_support()]\n",
        "print(\"\\nTop 10 Features (f_regression):\\n\", top_features)\n",
        "\n",
        "scores = pd.Series(selector.scores_, index=X_train.columns)\n",
        "scores = scores.sort_values(ascending=False)\n",
        "print(\"\\nRegression Feature Scores:\\n\", scores.head(10))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TlzU1fUHKDEt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eHnhvZ2aHdww"
      },
      "outputs": [],
      "source": [
        "#forward selection\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
        "sfs1 = SFS(RandomForestRegressor(n_jobs=-1, random_state=42),\n",
        "           k_features=5,\n",
        "           forward=True,\n",
        "           scoring='r2',\n",
        "           cv=3)\n",
        "\n",
        "sfs1 = sfs1.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best CV Score (R²):\", sfs1.k_score_)\n",
        "print(\"Selected Feature Indices:\", sfs1.k_feature_idx_)\n",
        "print(\"Selected Feature Names:\", sfs1.k_feature_names_)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Backward Selection\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
        "sfs1 = SFS(RandomForestRegressor(n_jobs=-1, random_state=42),\n",
        "           k_features=5,\n",
        "           forward=False,\n",
        "           scoring='r2',\n",
        "           cv=3)\n",
        "\n",
        "sfs1 = sfs1.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best CV Score (R²):\", sfs1.k_score_)\n",
        "print(\"Selected Feature Indices:\", sfs1.k_feature_idx_)\n",
        "print(\"Selected Feature Names:\", sfs1.k_feature_names_)\n"
      ],
      "metadata": {
        "id": "CVVsHiJ1Z6xu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ij4Zbz01HOs9"
      },
      "outputs": [],
      "source": [
        "#Exhaustive Feature Selection\n",
        "from mlxtend.feature_selection import ExhaustiveFeatureSelector as EFS\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "efs1=EFS(RandomForestClassifier(n_jobs=4),min_features=1,max_features=4,scoring='accuracy',cv=3)\n",
        "efs1=efs1.fit(X_train,y_train)\n",
        "print(efs1.best_idx_)\n",
        "print(efs1.best_score_)\n",
        "print(efs1.best_feature_names_)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Principal Component Analysis And Linear Discriminant Analysis\n",
        "import pandas as pd\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "df = pd.read_csv(\"train.csv\")\n",
        "\n",
        "X = df.select_dtypes(include=[\"int64\", \"float64\"]).drop(columns=[\"Id\", \"SalePrice\"])\n",
        "y = df[\"SalePrice\"]\n",
        "\n",
        "X = X.fillna(X.median())\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "pca = PCA(n_components=5)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "y_class = pd.qcut(y, q=3, labels=[\"Low\", \"Medium\", \"High\"])\n",
        "lda = LDA(n_components=2)\n",
        "X_lda = lda.fit_transform(X_scaled, y_class)\n",
        "\n",
        "print(\"Explained variance ratio (PCA):\", pca.explained_variance_ratio_)\n",
        "print(\"Shape after PCA:\", X_pca.shape)\n",
        "print(\"Shape after LDA:\", X_lda.shape)\n"
      ],
      "metadata": {
        "id": "FIvENicGViI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Linear Regression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error,mean_squared_error,r2_score\n",
        "model=LinearRegression()\n",
        "model.fit(X_train,y_train)\n",
        "y_pred=model.predict(X_train)\n",
        "new_pred=model.predict(X_test)\n",
        "mse=mean_squared_error(y_train,y_pred)\n",
        "mae=mean_absolute_error(y_train,y_pred)\n",
        "r2=r2_score(y_train,y_pred)\n",
        "print(\"mse is\",mse)\n",
        "print(\"mean absolute error is\",mae)\n",
        "print(\"r2_score is\",r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QYfCht9ulmm",
        "outputId": "d585c61d-806a-4c02-a7c5-f894e089db52"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mse is 316087245.50945115\n",
            "mean absolute error is 12079.324804579577\n",
            "r2_score is 0.9481803477598626\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "pDgXpOI0vWcD"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyOavn2n3avGkHsQvLsFQEcd",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}