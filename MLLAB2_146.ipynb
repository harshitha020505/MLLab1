{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP6x5R8M2zkaGGviNY3QiiK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harshitha020505/MLLab1/blob/main/MLLAB2_146.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCw0PdNQkLdH",
        "outputId": "a5d30251-e4dc-426b-efbc-327cb84e20dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4424, 37)\n",
            "Index(['Marital status', 'Application mode', 'Application order', 'Course',\n",
            "       'Daytime/evening attendance\\t', 'Previous qualification',\n",
            "       'Previous qualification (grade)', 'Nacionality',\n",
            "       'Mother's qualification', 'Father's qualification',\n",
            "       'Mother's occupation', 'Father's occupation', 'Admission grade',\n",
            "       'Displaced', 'Educational special needs', 'Debtor',\n",
            "       'Tuition fees up to date', 'Gender', 'Scholarship holder',\n",
            "       'Age at enrollment', 'International',\n",
            "       'Curricular units 1st sem (credited)',\n",
            "       'Curricular units 1st sem (enrolled)',\n",
            "       'Curricular units 1st sem (evaluations)',\n",
            "       'Curricular units 1st sem (approved)',\n",
            "       'Curricular units 1st sem (grade)',\n",
            "       'Curricular units 1st sem (without evaluations)',\n",
            "       'Curricular units 2nd sem (credited)',\n",
            "       'Curricular units 2nd sem (enrolled)',\n",
            "       'Curricular units 2nd sem (evaluations)',\n",
            "       'Curricular units 2nd sem (approved)',\n",
            "       'Curricular units 2nd sem (grade)',\n",
            "       'Curricular units 2nd sem (without evaluations)', 'Unemployment rate',\n",
            "       'Inflation rate', 'GDP', 'Target'],\n",
            "      dtype='object')\n",
            "      Marital status  Application mode  Application order  Course  \\\n",
            "0                  1                17                  5     171   \n",
            "1                  1                15                  1    9254   \n",
            "2                  1                 1                  5    9070   \n",
            "3                  1                17                  2    9773   \n",
            "4                  2                39                  1    8014   \n",
            "...              ...               ...                ...     ...   \n",
            "4419               1                 1                  6    9773   \n",
            "4420               1                 1                  2    9773   \n",
            "4421               1                 1                  1    9500   \n",
            "4422               1                 1                  1    9147   \n",
            "4423               1                10                  1    9773   \n",
            "\n",
            "      Daytime/evening attendance\\t  Previous qualification  \\\n",
            "0                                1                       1   \n",
            "1                                1                       1   \n",
            "2                                1                       1   \n",
            "3                                1                       1   \n",
            "4                                0                       1   \n",
            "...                            ...                     ...   \n",
            "4419                             1                       1   \n",
            "4420                             1                       1   \n",
            "4421                             1                       1   \n",
            "4422                             1                       1   \n",
            "4423                             1                       1   \n",
            "\n",
            "      Previous qualification (grade)  Nacionality  Mother's qualification  \\\n",
            "0                              122.0            1                      19   \n",
            "1                              160.0            1                       1   \n",
            "2                              122.0            1                      37   \n",
            "3                              122.0            1                      38   \n",
            "4                              100.0            1                      37   \n",
            "...                              ...          ...                     ...   \n",
            "4419                           125.0            1                       1   \n",
            "4420                           120.0          105                       1   \n",
            "4421                           154.0            1                      37   \n",
            "4422                           180.0            1                      37   \n",
            "4423                           152.0           22                      38   \n",
            "\n",
            "      Father's qualification  ...  Curricular units 2nd sem (credited)  \\\n",
            "0                         12  ...                                    0   \n",
            "1                          3  ...                                    0   \n",
            "2                         37  ...                                    0   \n",
            "3                         37  ...                                    0   \n",
            "4                         38  ...                                    0   \n",
            "...                      ...  ...                                  ...   \n",
            "4419                       1  ...                                    0   \n",
            "4420                       1  ...                                    0   \n",
            "4421                      37  ...                                    0   \n",
            "4422                      37  ...                                    0   \n",
            "4423                      37  ...                                    0   \n",
            "\n",
            "      Curricular units 2nd sem (enrolled)  \\\n",
            "0                                       0   \n",
            "1                                       6   \n",
            "2                                       6   \n",
            "3                                       6   \n",
            "4                                       6   \n",
            "...                                   ...   \n",
            "4419                                    6   \n",
            "4420                                    6   \n",
            "4421                                    8   \n",
            "4422                                    5   \n",
            "4423                                    6   \n",
            "\n",
            "      Curricular units 2nd sem (evaluations)  \\\n",
            "0                                          0   \n",
            "1                                          6   \n",
            "2                                          0   \n",
            "3                                         10   \n",
            "4                                          6   \n",
            "...                                      ...   \n",
            "4419                                       8   \n",
            "4420                                       6   \n",
            "4421                                       9   \n",
            "4422                                       6   \n",
            "4423                                       6   \n",
            "\n",
            "      Curricular units 2nd sem (approved)  Curricular units 2nd sem (grade)  \\\n",
            "0                                       0                          0.000000   \n",
            "1                                       6                         13.666667   \n",
            "2                                       0                          0.000000   \n",
            "3                                       5                         12.400000   \n",
            "4                                       6                         13.000000   \n",
            "...                                   ...                               ...   \n",
            "4419                                    5                         12.666667   \n",
            "4420                                    2                         11.000000   \n",
            "4421                                    1                         13.500000   \n",
            "4422                                    5                         12.000000   \n",
            "4423                                    6                         13.000000   \n",
            "\n",
            "      Curricular units 2nd sem (without evaluations)  Unemployment rate  \\\n",
            "0                                                  0               10.8   \n",
            "1                                                  0               13.9   \n",
            "2                                                  0               10.8   \n",
            "3                                                  0                9.4   \n",
            "4                                                  0               13.9   \n",
            "...                                              ...                ...   \n",
            "4419                                               0               15.5   \n",
            "4420                                               0               11.1   \n",
            "4421                                               0               13.9   \n",
            "4422                                               0                9.4   \n",
            "4423                                               0               12.7   \n",
            "\n",
            "      Inflation rate   GDP    Target  \n",
            "0                1.4  1.74   Dropout  \n",
            "1               -0.3  0.79  Graduate  \n",
            "2                1.4  1.74   Dropout  \n",
            "3               -0.8 -3.12  Graduate  \n",
            "4               -0.3  0.79  Graduate  \n",
            "...              ...   ...       ...  \n",
            "4419             2.8 -4.06  Graduate  \n",
            "4420             0.6  2.02   Dropout  \n",
            "4421            -0.3  0.79   Dropout  \n",
            "4422            -0.8 -3.12  Graduate  \n",
            "4423             3.7 -1.70  Graduate  \n",
            "\n",
            "[4424 rows x 37 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv(\"data.csv\",delimiter=\";\",quotechar='\"',encoding=\"utf-8\")\n",
        "print(df.shape)\n",
        "print(df.columns)\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a9hk3tOwuNFd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#constant features\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "df=pd.read_csv(\"data.csv\",delimiter=\";\",quotechar='\"',encoding=\"utf-8\")\n",
        "print(df.shape)\n",
        "[col for col in df.columns if df[col].isnull().sum()>0]\n",
        "X = df.drop('Target', axis=1)\n",
        "y = df['Target']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
        "constant_features=[features for features in X_train.columns if X_train[features].std()==0]\n",
        "print(len(constant_features))\n",
        "print(constant_features)\n",
        "X_train.drop(columns=constant_features, inplace=True)\n",
        "X_test.drop(columns=constant_features, inplace=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNGEMKb0mw7c",
        "outputId": "daa65500-cbfe-4c1a-dc0d-789cd8fb190e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4424, 37)\n",
            "0\n",
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#quasi-constant features\n",
        "X = df.drop('Target', axis=1)\n",
        "y = df['Target']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
        "quasi_constant_features=[]\n",
        "for feature in X_train.columns:\n",
        "  predominant=(X_train[feature].value_counts()/float(len(X_train))).sort_values(ascending=False).values[0]\n",
        "  if(predominant>0.99):\n",
        "    quasi_constant_features.append(feature)\n",
        "print(len(quasi_constant_features))\n",
        "print(quasi_constant_features)\n",
        "X_train.drop(columns=quasi_constant_features, inplace=True)\n",
        "X_test.drop(columns=quasi_constant_features, inplace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwBFglztwtLV",
        "outputId": "bf969ecd-7faa-4096-f8d1-bb8028c45463"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#duplicated features\n",
        "dup=[]\n",
        "for i in range(0,len(X_train.columns)):\n",
        "  col1=X_train.columns[i]\n",
        "  for col2 in X_train.columns[i+1:]:\n",
        "    if(X_train[col1].equals(X_train[col2])):\n",
        "      dup.append(col2)\n",
        "print(len(dup))\n",
        "print(dup)\n",
        "X_train.drop(columns=dup, inplace=True)\n",
        "X_test.drop(columns=dup, inplace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k03MxbQ61Eb3",
        "outputId": "8767c46c-a01d-4c52-e294-cab487313bfa"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation\n",
        "grouped_feature_ls = []\n",
        "correlated_groups = []\n",
        "\n",
        "def correlation(dataset, threshold):\n",
        "    col_corr = set()\n",
        "    numeric_df = dataset.select_dtypes(include=['number'])  # Only numeric columns\n",
        "    col_matrix = numeric_df.corr()\n",
        "    for i in range(len(col_matrix.columns)):\n",
        "        for j in range(i):\n",
        "            if abs(col_matrix.iloc[i, j]\n",
        "                   ) > threshold:\n",
        "                colname = col_matrix.columns[i]\n",
        "                col_corr.add(colname)\n",
        "    return col_corr\n",
        "\n",
        "corr_features = correlation(df, 0.9)\n",
        "corr_final = set(corr_features)\n",
        "print(len(corr_final))\n",
        "X_train.drop(columns=corr_final, inplace=True)\n",
        "X_test.drop(columns=corr_final, inplace=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "c7SKuXG53YwA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed49fd28-8ef4-4082-8bbe-7772fc38dcfa"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Mutual Information\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "import pandas as pd\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "\n",
        "X = df.drop('Target', axis=1)\n",
        "y = df['Target']\n",
        "mi_scores = mutual_info_classif(X, y)\n",
        "mi_scores = pd.Series(mi_scores, index=X.columns)\n",
        "mi_scores = mi_scores.sort_values(ascending=False)\n",
        "\n",
        "# print(mi_scores)\n",
        "sel_ = SelectKBest(mutual_info_classif, k=10).fit(X_train.fillna(0), y_train)\n",
        "X_train.columns[sel_.get_support()]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xuGUZHm68X5H",
        "outputId": "bbee6376-25c3-4a6f-d430-beea832f9b80"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Application mode', 'Course', 'Tuition fees up to date',\n",
              "       'Scholarship holder', 'Curricular units 1st sem (enrolled)',\n",
              "       'Curricular units 1st sem (evaluations)',\n",
              "       'Curricular units 1st sem (approved)',\n",
              "       'Curricular units 1st sem (grade)',\n",
              "       'Curricular units 2nd sem (evaluations)',\n",
              "       'Curricular units 2nd sem (grade)'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#constant features\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "df1=pd.read_csv(\"student-por.csv\",delimiter=\";\",quotechar='\"',encoding=\"utf-8\")\n",
        "print(df1.columns)\n",
        "[col for col in df1.columns if df1[col].isnull().sum()>0]\n",
        "X = df1.drop('G3', axis=1)\n",
        "X = pd.get_dummies(X, drop_first=True)\n",
        "y = df1['G3']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
        "constant_features=[features for features in X_train.columns if X_train[features].std()==0]\n",
        "print(len(constant_features))\n",
        "print(constant_features)\n",
        "X_train.drop(columns=constant_features, inplace=True)\n",
        "X_test.drop(columns=constant_features, inplace=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqVyne3SYyxs",
        "outputId": "d6eb9847-d322-4e98-c808-ed6a94ae9b64"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['school', 'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu',\n",
            "       'Mjob', 'Fjob', 'reason', 'guardian', 'traveltime', 'studytime',\n",
            "       'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery',\n",
            "       'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc',\n",
            "       'Walc', 'health', 'absences', 'G1', 'G2', 'G3'],\n",
            "      dtype='object')\n",
            "0\n",
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "QqmGiake9jVh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#quasi-constant features\n",
        "X = df1.drop('G3', axis=1)\n",
        "y = df1['G3']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
        "quasi_constant_features=[]\n",
        "for feature in X_train.columns:\n",
        "  predominant=(X_train[feature].value_counts()/float(len(X_train))).sort_values(ascending=False).values[0]\n",
        "  if(predominant>0.99):\n",
        "    quasi_constant_features.append(feature)\n",
        "print(len(quasi_constant_features))\n",
        "print(quasi_constant_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uz3SEWAcbxB5",
        "outputId": "8e939cb6-50d4-4324-89e2-9fce27467d5c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#duplicated features\n",
        "dup=[]\n",
        "for i in range(0,len(X_train.columns)):\n",
        "  col1=X_train.columns[i]\n",
        "  for col2 in X_train.columns[i+1:]:\n",
        "    if(X_train[col1].equals(X_train[col2])):\n",
        "      dup.append(col2)\n",
        "print(len(dup))\n",
        "print(dup)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XwMPA9VKb-Pj",
        "outputId": "8b39176c-9c18-44d7-865a-dd7b1fb5b024"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation\n",
        "grouped_feature_ls = []\n",
        "correlated_groups = []\n",
        "\n",
        "def correlation(dataset, threshold):\n",
        "    col_corr = set()\n",
        "    numeric_df = dataset.select_dtypes(include=['number'])  # Only numeric columns\n",
        "    col_matrix = numeric_df.corr()\n",
        "    for i in range(len(col_matrix.columns)):\n",
        "        for j in range(i):\n",
        "            if abs(col_matrix.iloc[i, j]) > threshold:\n",
        "                colname = col_matrix.columns[i]\n",
        "                col_corr.add(colname)\n",
        "    return col_corr\n",
        "\n",
        "corr_features = correlation(df1, 0.9)\n",
        "corr_final = set(corr_features)\n",
        "print(len(corr_final))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3HmRF4ZcIoj",
        "outputId": "75630ee6-8e17-4455-e192-043311a75523"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Mutual Information\n",
        "from sklearn.feature_selection import mutual_info_classif, SelectKBest\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "X = df1.drop('G3', axis=1)\n",
        "X = pd.get_dummies(X, drop_first=True)\n",
        "y = df1['G3']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
        "\n",
        "mi_scores = mutual_info_classif(X_train.fillna(0), y_train)\n",
        "mi_scores = pd.Series(mi_scores, index=X_train.columns)\n",
        "mi_scores = mi_scores.sort_values(ascending=False)\n",
        "\n",
        "print(\"Top MI scores:\\n\", mi_scores.head(10))\n",
        "\n",
        "\n",
        "selector = SelectKBest(mutual_info_classif, k=10)\n",
        "selector.fit(X_train.fillna(0), y_train)\n",
        "\n",
        "top_features = X_train.columns[selector.get_support()]\n",
        "print(\"Top 10 selected features:\\n\", top_features)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CgkXgtqinyg8",
        "outputId": "30055193-1a3c-4e3a-f5ad-ec472078ba79"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top MI scores:\n",
            " G2                 1.240936\n",
            "G1                 0.833234\n",
            "school_MS          0.122489\n",
            "Dalc               0.122137\n",
            "Walc               0.113210\n",
            "internet_yes       0.111683\n",
            "higher_yes         0.099148\n",
            "failures           0.099113\n",
            "guardian_mother    0.096148\n",
            "address_U          0.092319\n",
            "dtype: float64\n",
            "Top 10 selected features:\n",
            " Index(['age', 'Medu', 'failures', 'Dalc', 'health', 'G1', 'G2', 'Pstatus_T',\n",
            "       'Mjob_services', 'higher_yes'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#constant features\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "df2=pd.read_csv(\"AirQualityUCI.csv\",delimiter=\";\",quotechar='\"',encoding=\"utf-8\")\n",
        "print(df2.columns)\n",
        "[col for col in df2.columns if df2[col].isnull().sum()>0]\n",
        "X = df2.drop('CO(GT)', axis=1)\n",
        "X = pd.get_dummies(X, drop_first=True)\n",
        "y = df2['CO(GT)']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
        "constant_features=[features for features in X_train.columns if X_train[features].std()==0]\n",
        "print(len(constant_features))\n",
        "print(constant_features)\n",
        "X_train.drop(columns=constant_features, inplace=True)\n",
        "X_test.drop(columns=constant_features, inplace=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "jQnoxfeVcVk_",
        "outputId": "e999dbc9-fe69-4093-ec1e-e125590ea971"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Date', 'Time', 'CO(GT)', 'PT08.S1(CO)', 'NMHC(GT)', 'C6H6(GT)',\n",
            "       'PT08.S2(NMHC)', 'NOx(GT)', 'PT08.S3(NOx)', 'NO2(GT)', 'PT08.S4(NO2)',\n",
            "       'PT08.S5(O3)', 'T', 'RH', 'AH', 'Unnamed: 15', 'Unnamed: 16'],\n",
            "      dtype='object')\n",
            "1683\n",
            "['C6H6(GT)_29,2', 'C6H6(GT)_30,5', 'C6H6(GT)_31,6', 'C6H6(GT)_33,0', 'C6H6(GT)_34,5', 'C6H6(GT)_36,4', 'C6H6(GT)_37,2', 'C6H6(GT)_37,4', 'C6H6(GT)_38,3', 'C6H6(GT)_39,2', 'C6H6(GT)_43,7', 'C6H6(GT)_44,9', 'C6H6(GT)_45,0', 'C6H6(GT)_48,2', 'T_-0,2', 'T_-0,3', 'T_-0,5', 'T_-1,4', 'T_-1,9', 'T_0,7', 'T_1,1', 'T_36,7', 'T_40,7', 'T_41,0', 'T_41,7', 'T_41,8', 'T_42,6', 'T_44,3', 'T_44,6', 'RH_11,1', 'RH_11,6', 'RH_11,8', 'RH_12,2', 'RH_12,5', 'RH_12,9', 'RH_13,4', 'RH_17,8', 'RH_81,9', 'RH_85,5', 'RH_85,6', 'RH_86,5', 'RH_9,6', 'AH_0,2086', 'AH_0,2157', 'AH_0,2180', 'AH_0,2193', 'AH_0,2240', 'AH_0,2244', 'AH_0,2246', 'AH_0,2269', 'AH_0,2292', 'AH_0,2347', 'AH_0,2363', 'AH_0,2382', 'AH_0,2386', 'AH_0,2420', 'AH_0,2478', 'AH_0,2503', 'AH_0,2536', 'AH_0,2547', 'AH_0,2566', 'AH_0,2592', 'AH_0,2606', 'AH_0,2611', 'AH_0,2677', 'AH_0,2693', 'AH_0,2698', 'AH_0,2716', 'AH_0,2726', 'AH_0,2740', 'AH_0,2749', 'AH_0,2763', 'AH_0,2801', 'AH_0,2906', 'AH_0,2933', 'AH_0,2955', 'AH_0,2956', 'AH_0,2977', 'AH_0,2987', 'AH_0,2991', 'AH_0,2999', 'AH_0,3017', 'AH_0,3074', 'AH_0,3079', 'AH_0,3093', 'AH_0,3114', 'AH_0,3123', 'AH_0,3152', 'AH_0,3216', 'AH_0,3228', 'AH_0,3249', 'AH_0,3250', 'AH_0,3271', 'AH_0,3287', 'AH_0,3290', 'AH_0,3299', 'AH_0,3318', 'AH_0,3320', 'AH_0,3330', 'AH_0,3341', 'AH_0,3344', 'AH_0,3370', 'AH_0,3390', 'AH_0,3391', 'AH_0,3420', 'AH_0,3426', 'AH_0,3448', 'AH_0,3488', 'AH_0,3489', 'AH_0,3499', 'AH_0,3521', 'AH_0,3529', 'AH_0,3545', 'AH_0,3556', 'AH_0,3566', 'AH_0,3581', 'AH_0,3594', 'AH_0,3634', 'AH_0,3635', 'AH_0,3642', 'AH_0,3652', 'AH_0,3656', 'AH_0,3661', 'AH_0,3666', 'AH_0,3668', 'AH_0,3707', 'AH_0,3714', 'AH_0,3716', 'AH_0,3725', 'AH_0,3740', 'AH_0,3748', 'AH_0,3754', 'AH_0,3760', 'AH_0,3771', 'AH_0,3774', 'AH_0,3779', 'AH_0,3795', 'AH_0,3813', 'AH_0,3832', 'AH_0,3850', 'AH_0,3858', 'AH_0,3862', 'AH_0,3871', 'AH_0,3882', 'AH_0,3904', 'AH_0,3915', 'AH_0,3926', 'AH_0,3934', 'AH_0,3948', 'AH_0,3955', 'AH_0,3960', 'AH_0,3968', 'AH_0,3972', 'AH_0,3980', 'AH_0,3981', 'AH_0,3990', 'AH_0,4023', 'AH_0,4026', 'AH_0,4034', 'AH_0,4054', 'AH_0,4069', 'AH_0,4072', 'AH_0,4075', 'AH_0,4076', 'AH_0,4077', 'AH_0,4079', 'AH_0,4112', 'AH_0,4115', 'AH_0,4118', 'AH_0,4120', 'AH_0,4125', 'AH_0,4134', 'AH_0,4138', 'AH_0,4141', 'AH_0,4144', 'AH_0,4172', 'AH_0,4178', 'AH_0,4185', 'AH_0,4190', 'AH_0,4203', 'AH_0,4205', 'AH_0,4208', 'AH_0,4210', 'AH_0,4211', 'AH_0,4212', 'AH_0,4219', 'AH_0,4228', 'AH_0,4256', 'AH_0,4260', 'AH_0,4263', 'AH_0,4280', 'AH_0,4290', 'AH_0,4294', 'AH_0,4298', 'AH_0,4304', 'AH_0,4321', 'AH_0,4333', 'AH_0,4334', 'AH_0,4344', 'AH_0,4345', 'AH_0,4346', 'AH_0,4354', 'AH_0,4356', 'AH_0,4360', 'AH_0,4372', 'AH_0,4373', 'AH_0,4378', 'AH_0,4385', 'AH_0,4387', 'AH_0,4389', 'AH_0,4390', 'AH_0,4398', 'AH_0,4399', 'AH_0,4401', 'AH_0,4405', 'AH_0,4411', 'AH_0,4417', 'AH_0,4419', 'AH_0,4424', 'AH_0,4425', 'AH_0,4431', 'AH_0,4448', 'AH_0,4451', 'AH_0,4480', 'AH_0,4488', 'AH_0,4490', 'AH_0,4491', 'AH_0,4542', 'AH_0,4559', 'AH_0,4561', 'AH_0,4567', 'AH_0,4571', 'AH_0,4572', 'AH_0,4584', 'AH_0,4589', 'AH_0,4591', 'AH_0,4595', 'AH_0,4599', 'AH_0,4614', 'AH_0,4623', 'AH_0,4633', 'AH_0,4656', 'AH_0,4657', 'AH_0,4660', 'AH_0,4667', 'AH_0,4670', 'AH_0,4698', 'AH_0,4704', 'AH_0,4706', 'AH_0,4717', 'AH_0,4756', 'AH_0,4760', 'AH_0,4768', 'AH_0,4769', 'AH_0,4782', 'AH_0,4790', 'AH_0,4794', 'AH_0,4818', 'AH_0,4821', 'AH_0,4830', 'AH_0,4847', 'AH_0,4854', 'AH_0,4860', 'AH_0,4869', 'AH_0,4876', 'AH_0,4877', 'AH_0,4882', 'AH_0,4892', 'AH_0,4915', 'AH_0,4922', 'AH_0,4926', 'AH_0,4927', 'AH_0,4932', 'AH_0,4945', 'AH_0,4950', 'AH_0,4975', 'AH_0,4977', 'AH_0,4979', 'AH_0,5013', 'AH_0,5020', 'AH_0,5023', 'AH_0,5037', 'AH_0,5039', 'AH_0,5061', 'AH_0,5074', 'AH_0,5091', 'AH_0,5108', 'AH_0,5113', 'AH_0,5114', 'AH_0,5115', 'AH_0,5117', 'AH_0,5125', 'AH_0,5128', 'AH_0,5134', 'AH_0,5153', 'AH_0,5166', 'AH_0,5209', 'AH_0,5212', 'AH_0,5226', 'AH_0,5242', 'AH_0,5251', 'AH_0,5272', 'AH_0,5274', 'AH_0,5281', 'AH_0,5282', 'AH_0,5292', 'AH_0,5307', 'AH_0,5314', 'AH_0,5329', 'AH_0,5346', 'AH_0,5370', 'AH_0,5383', 'AH_0,5396', 'AH_0,5416', 'AH_0,5417', 'AH_0,5432', 'AH_0,5462', 'AH_0,5463', 'AH_0,5488', 'AH_0,5498', 'AH_0,5499', 'AH_0,5522', 'AH_0,5555', 'AH_0,5572', 'AH_0,5589', 'AH_0,5595', 'AH_0,5598', 'AH_0,5610', 'AH_0,5612', 'AH_0,5618', 'AH_0,5626', 'AH_0,5631', 'AH_0,5632', 'AH_0,5637', 'AH_0,5654', 'AH_0,5656', 'AH_0,5664', 'AH_0,5680', 'AH_0,5708', 'AH_0,5720', 'AH_0,5734', 'AH_0,5753', 'AH_0,5781', 'AH_0,5784', 'AH_0,5797', 'AH_0,5813', 'AH_0,5823', 'AH_0,5838', 'AH_0,5852', 'AH_0,5870', 'AH_0,5871', 'AH_0,5890', 'AH_0,5901', 'AH_0,5902', 'AH_0,5914', 'AH_0,5929', 'AH_0,5930', 'AH_0,5931', 'AH_0,5935', 'AH_0,5936', 'AH_0,5937', 'AH_0,5976', 'AH_0,5986', 'AH_0,5998', 'AH_0,6010', 'AH_0,6028', 'AH_0,6033', 'AH_0,6040', 'AH_0,6045', 'AH_0,6056', 'AH_0,6063', 'AH_0,6073', 'AH_0,6077', 'AH_0,6082', 'AH_0,6111', 'AH_0,6113', 'AH_0,6141', 'AH_0,6150', 'AH_0,6159', 'AH_0,6163', 'AH_0,6167', 'AH_0,6188', 'AH_0,6192', 'AH_0,6195', 'AH_0,6198', 'AH_0,6228', 'AH_0,6232', 'AH_0,6244', 'AH_0,6255', 'AH_0,6258', 'AH_0,6261', 'AH_0,6275', 'AH_0,6293', 'AH_0,6298', 'AH_0,6300', 'AH_0,6308', 'AH_0,6311', 'AH_0,6312', 'AH_0,6324', 'AH_0,6349', 'AH_0,6353', 'AH_0,6356', 'AH_0,6369', 'AH_0,6374', 'AH_0,6376', 'AH_0,6395', 'AH_0,6396', 'AH_0,6397', 'AH_0,6410', 'AH_0,6442', 'AH_0,6451', 'AH_0,6470', 'AH_0,6471', 'AH_0,6498', 'AH_0,6499', 'AH_0,6514', 'AH_0,6517', 'AH_0,6521', 'AH_0,6530', 'AH_0,6537', 'AH_0,6541', 'AH_0,6556', 'AH_0,6560', 'AH_0,6561', 'AH_0,6578', 'AH_0,6600', 'AH_0,6609', 'AH_0,6617', 'AH_0,6626', 'AH_0,6647', 'AH_0,6648', 'AH_0,6649', 'AH_0,6653', 'AH_0,6665', 'AH_0,6669', 'AH_0,6677', 'AH_0,6682', 'AH_0,6683', 'AH_0,6691', 'AH_0,6706', 'AH_0,6717', 'AH_0,6718', 'AH_0,6725', 'AH_0,6729', 'AH_0,6733', 'AH_0,6735', 'AH_0,6751', 'AH_0,6753', 'AH_0,6761', 'AH_0,6766', 'AH_0,6775', 'AH_0,6777', 'AH_0,6779', 'AH_0,6780', 'AH_0,6781', 'AH_0,6787', 'AH_0,6811', 'AH_0,6814', 'AH_0,6815', 'AH_0,6821', 'AH_0,6824', 'AH_0,6842', 'AH_0,6853', 'AH_0,6856', 'AH_0,6864', 'AH_0,6868', 'AH_0,6869', 'AH_0,6883', 'AH_0,6890', 'AH_0,6896', 'AH_0,6927', 'AH_0,6931', 'AH_0,6938', 'AH_0,6959', 'AH_0,6990', 'AH_0,7012', 'AH_0,7023', 'AH_0,7024', 'AH_0,7028', 'AH_0,7033', 'AH_0,7035', 'AH_0,7041', 'AH_0,7051', 'AH_0,7052', 'AH_0,7067', 'AH_0,7071', 'AH_0,7093', 'AH_0,7098', 'AH_0,7106', 'AH_0,7107', 'AH_0,7112', 'AH_0,7118', 'AH_0,7131', 'AH_0,7133', 'AH_0,7151', 'AH_0,7152', 'AH_0,7157', 'AH_0,7177', 'AH_0,7182', 'AH_0,7184', 'AH_0,7185', 'AH_0,7192', 'AH_0,7201', 'AH_0,7202', 'AH_0,7220', 'AH_0,7224', 'AH_0,7231', 'AH_0,7232', 'AH_0,7234', 'AH_0,7247', 'AH_0,7252', 'AH_0,7254', 'AH_0,7257', 'AH_0,7268', 'AH_0,7271', 'AH_0,7273', 'AH_0,7278', 'AH_0,7325', 'AH_0,7349', 'AH_0,7362', 'AH_0,7363', 'AH_0,7367', 'AH_0,7389', 'AH_0,7390', 'AH_0,7394', 'AH_0,7402', 'AH_0,7406', 'AH_0,7408', 'AH_0,7415', 'AH_0,7426', 'AH_0,7438', 'AH_0,7443', 'AH_0,7448', 'AH_0,7451', 'AH_0,7455', 'AH_0,7461', 'AH_0,7464', 'AH_0,7473', 'AH_0,7478', 'AH_0,7506', 'AH_0,7509', 'AH_0,7517', 'AH_0,7536', 'AH_0,7542', 'AH_0,7547', 'AH_0,7577', 'AH_0,7597', 'AH_0,7599', 'AH_0,7609', 'AH_0,7611', 'AH_0,7615', 'AH_0,7619', 'AH_0,7627', 'AH_0,7638', 'AH_0,7669', 'AH_0,7676', 'AH_0,7686', 'AH_0,7691', 'AH_0,7692', 'AH_0,7705', 'AH_0,7727', 'AH_0,7749', 'AH_0,7751', 'AH_0,7755', 'AH_0,7756', 'AH_0,7757', 'AH_0,7767', 'AH_0,7777', 'AH_0,7779', 'AH_0,7789', 'AH_0,7792', 'AH_0,7800', 'AH_0,7811', 'AH_0,7820', 'AH_0,7825', 'AH_0,7830', 'AH_0,7849', 'AH_0,7853', 'AH_0,7860', 'AH_0,7882', 'AH_0,7885', 'AH_0,7897', 'AH_0,7902', 'AH_0,7904', 'AH_0,7913', 'AH_0,7914', 'AH_0,7920', 'AH_0,7934', 'AH_0,7938', 'AH_0,7943', 'AH_0,7951', 'AH_0,7958', 'AH_0,7963', 'AH_0,7967', 'AH_0,7968', 'AH_0,7976', 'AH_0,8002', 'AH_0,8009', 'AH_0,8014', 'AH_0,8015', 'AH_0,8026', 'AH_0,8030', 'AH_0,8041', 'AH_0,8057', 'AH_0,8058', 'AH_0,8059', 'AH_0,8066', 'AH_0,8067', 'AH_0,8071', 'AH_0,8077', 'AH_0,8086', 'AH_0,8090', 'AH_0,8099', 'AH_0,8103', 'AH_0,8116', 'AH_0,8162', 'AH_0,8163', 'AH_0,8164', 'AH_0,8167', 'AH_0,8173', 'AH_0,8185', 'AH_0,8199', 'AH_0,8222', 'AH_0,8224', 'AH_0,8225', 'AH_0,8227', 'AH_0,8232', 'AH_0,8239', 'AH_0,8240', 'AH_0,8250', 'AH_0,8282', 'AH_0,8291', 'AH_0,8292', 'AH_0,8320', 'AH_0,8321', 'AH_0,8324', 'AH_0,8345', 'AH_0,8347', 'AH_0,8349', 'AH_0,8353', 'AH_0,8371', 'AH_0,8386', 'AH_0,8417', 'AH_0,8426', 'AH_0,8441', 'AH_0,8443', 'AH_0,8458', 'AH_0,8471', 'AH_0,8474', 'AH_0,8497', 'AH_0,8509', 'AH_0,8510', 'AH_0,8517', 'AH_0,8523', 'AH_0,8529', 'AH_0,8533', 'AH_0,8535', 'AH_0,8540', 'AH_0,8545', 'AH_0,8561', 'AH_0,8564', 'AH_0,8569', 'AH_0,8574', 'AH_0,8590', 'AH_0,8616', 'AH_0,8619', 'AH_0,8620', 'AH_0,8636', 'AH_0,8640', 'AH_0,8642', 'AH_0,8662', 'AH_0,8678', 'AH_0,8681', 'AH_0,8698', 'AH_0,8704', 'AH_0,8705', 'AH_0,8718', 'AH_0,8740', 'AH_0,8744', 'AH_0,8748', 'AH_0,8750', 'AH_0,8759', 'AH_0,8761', 'AH_0,8766', 'AH_0,8767', 'AH_0,8784', 'AH_0,8787', 'AH_0,8803', 'AH_0,8811', 'AH_0,8814', 'AH_0,8816', 'AH_0,8818', 'AH_0,8821', 'AH_0,8830', 'AH_0,8845', 'AH_0,8856', 'AH_0,8859', 'AH_0,8861', 'AH_0,8872', 'AH_0,8874', 'AH_0,8883', 'AH_0,8893', 'AH_0,8894', 'AH_0,8899', 'AH_0,8907', 'AH_0,8910', 'AH_0,8925', 'AH_0,8932', 'AH_0,8939', 'AH_0,8945', 'AH_0,8959', 'AH_0,8960', 'AH_0,8969', 'AH_0,8980', 'AH_0,8981', 'AH_0,8987', 'AH_0,8995', 'AH_0,8997', 'AH_0,8998', 'AH_0,9003', 'AH_0,9009', 'AH_0,9012', 'AH_0,9017', 'AH_0,9027', 'AH_0,9038', 'AH_0,9046', 'AH_0,9050', 'AH_0,9056', 'AH_0,9083', 'AH_0,9094', 'AH_0,9097', 'AH_0,9103', 'AH_0,9107', 'AH_0,9133', 'AH_0,9137', 'AH_0,9141', 'AH_0,9155', 'AH_0,9168', 'AH_0,9172', 'AH_0,9174', 'AH_0,9177', 'AH_0,9183', 'AH_0,9186', 'AH_0,9195', 'AH_0,9196', 'AH_0,9198', 'AH_0,9202', 'AH_0,9208', 'AH_0,9210', 'AH_0,9214', 'AH_0,9238', 'AH_0,9242', 'AH_0,9286', 'AH_0,9292', 'AH_0,9296', 'AH_0,9309', 'AH_0,9328', 'AH_0,9342', 'AH_0,9354', 'AH_0,9355', 'AH_0,9364', 'AH_0,9367', 'AH_0,9372', 'AH_0,9373', 'AH_0,9380', 'AH_0,9384', 'AH_0,9388', 'AH_0,9399', 'AH_0,9402', 'AH_0,9405', 'AH_0,9425', 'AH_0,9433', 'AH_0,9441', 'AH_0,9446', 'AH_0,9447', 'AH_0,9466', 'AH_0,9468', 'AH_0,9500', 'AH_0,9504', 'AH_0,9521', 'AH_0,9523', 'AH_0,9532', 'AH_0,9536', 'AH_0,9537', 'AH_0,9542', 'AH_0,9544', 'AH_0,9561', 'AH_0,9562', 'AH_0,9567', 'AH_0,9575', 'AH_0,9581', 'AH_0,9587', 'AH_0,9595', 'AH_0,9622', 'AH_0,9623', 'AH_0,9628', 'AH_0,9643', 'AH_0,9660', 'AH_0,9664', 'AH_0,9665', 'AH_0,9683', 'AH_0,9689', 'AH_0,9697', 'AH_0,9704', 'AH_0,9708', 'AH_0,9711', 'AH_0,9720', 'AH_0,9728', 'AH_0,9733', 'AH_0,9749', 'AH_0,9751', 'AH_0,9788', 'AH_0,9791', 'AH_0,9793', 'AH_0,9796', 'AH_0,9798', 'AH_0,9800', 'AH_0,9807', 'AH_0,9808', 'AH_0,9818', 'AH_0,9828', 'AH_0,9860', 'AH_0,9862', 'AH_0,9865', 'AH_0,9866', 'AH_0,9877', 'AH_0,9878', 'AH_0,9883', 'AH_0,9906', 'AH_0,9923', 'AH_0,9931', 'AH_0,9934', 'AH_0,9944', 'AH_0,9949', 'AH_0,9956', 'AH_0,9960', 'AH_0,9969', 'AH_0,9981', 'AH_1,0004', 'AH_1,0008', 'AH_1,0009', 'AH_1,0017', 'AH_1,0029', 'AH_1,0030', 'AH_1,0036', 'AH_1,0041', 'AH_1,0071', 'AH_1,0080', 'AH_1,0097', 'AH_1,0100', 'AH_1,0119', 'AH_1,0132', 'AH_1,0153', 'AH_1,0166', 'AH_1,0179', 'AH_1,0188', 'AH_1,0201', 'AH_1,0223', 'AH_1,0230', 'AH_1,0231', 'AH_1,0232', 'AH_1,0239', 'AH_1,0259', 'AH_1,0276', 'AH_1,0277', 'AH_1,0298', 'AH_1,0303', 'AH_1,0309', 'AH_1,0312', 'AH_1,0317', 'AH_1,0331', 'AH_1,0338', 'AH_1,0342', 'AH_1,0347', 'AH_1,0351', 'AH_1,0354', 'AH_1,0362', 'AH_1,0367', 'AH_1,0370', 'AH_1,0385', 'AH_1,0389', 'AH_1,0398', 'AH_1,0405', 'AH_1,0436', 'AH_1,0441', 'AH_1,0462', 'AH_1,0465', 'AH_1,0468', 'AH_1,0473', 'AH_1,0477', 'AH_1,0482', 'AH_1,0487', 'AH_1,0491', 'AH_1,0502', 'AH_1,0504', 'AH_1,0510', 'AH_1,0518', 'AH_1,0531', 'AH_1,0536', 'AH_1,0557', 'AH_1,0563', 'AH_1,0575', 'AH_1,0576', 'AH_1,0580', 'AH_1,0581', 'AH_1,0582', 'AH_1,0586', 'AH_1,0596', 'AH_1,0609', 'AH_1,0610', 'AH_1,0613', 'AH_1,0614', 'AH_1,0628', 'AH_1,0643', 'AH_1,0668', 'AH_1,0669', 'AH_1,0670', 'AH_1,0674', 'AH_1,0679', 'AH_1,0680', 'AH_1,0689', 'AH_1,0700', 'AH_1,0703', 'AH_1,0708', 'AH_1,0723', 'AH_1,0728', 'AH_1,0781', 'AH_1,0784', 'AH_1,0789', 'AH_1,0790', 'AH_1,0794', 'AH_1,0801', 'AH_1,0817', 'AH_1,0821', 'AH_1,0840', 'AH_1,0842', 'AH_1,0844', 'AH_1,0846', 'AH_1,0847', 'AH_1,0850', 'AH_1,0851', 'AH_1,0857', 'AH_1,0858', 'AH_1,0885', 'AH_1,0887', 'AH_1,0899', 'AH_1,0909', 'AH_1,0927', 'AH_1,0929', 'AH_1,0955', 'AH_1,0965', 'AH_1,0966', 'AH_1,0970', 'AH_1,0972', 'AH_1,1010', 'AH_1,1019', 'AH_1,1020', 'AH_1,1037', 'AH_1,1044', 'AH_1,1078', 'AH_1,1082', 'AH_1,1087', 'AH_1,1095', 'AH_1,1097', 'AH_1,1115', 'AH_1,1121', 'AH_1,1138', 'AH_1,1147', 'AH_1,1164', 'AH_1,1167', 'AH_1,1171', 'AH_1,1177', 'AH_1,1204', 'AH_1,1216', 'AH_1,1221', 'AH_1,1228', 'AH_1,1229', 'AH_1,1237', 'AH_1,1242', 'AH_1,1249', 'AH_1,1255', 'AH_1,1273', 'AH_1,1276', 'AH_1,1284', 'AH_1,1293', 'AH_1,1302', 'AH_1,1321', 'AH_1,1322', 'AH_1,1326', 'AH_1,1331', 'AH_1,1347', 'AH_1,1353', 'AH_1,1377', 'AH_1,1379', 'AH_1,1387', 'AH_1,1389', 'AH_1,1403', 'AH_1,1407', 'AH_1,1410', 'AH_1,1416', 'AH_1,1438', 'AH_1,1453', 'AH_1,1459', 'AH_1,1477', 'AH_1,1501', 'AH_1,1510', 'AH_1,1517', 'AH_1,1518', 'AH_1,1523', 'AH_1,1533', 'AH_1,1547', 'AH_1,1548', 'AH_1,1553', 'AH_1,1561', 'AH_1,1582', 'AH_1,1600', 'AH_1,1605', 'AH_1,1630', 'AH_1,1631', 'AH_1,1633', 'AH_1,1638', 'AH_1,1642', 'AH_1,1644', 'AH_1,1674', 'AH_1,1677', 'AH_1,1684', 'AH_1,1691', 'AH_1,1694', 'AH_1,1706', 'AH_1,1731', 'AH_1,1742', 'AH_1,1768', 'AH_1,1781', 'AH_1,1790', 'AH_1,1830', 'AH_1,1844', 'AH_1,1849', 'AH_1,1855', 'AH_1,1864', 'AH_1,1869', 'AH_1,1878', 'AH_1,1886', 'AH_1,1895', 'AH_1,1901', 'AH_1,1910', 'AH_1,1913', 'AH_1,1932', 'AH_1,1937', 'AH_1,1952', 'AH_1,1954', 'AH_1,1965', 'AH_1,1970', 'AH_1,1973', 'AH_1,1989', 'AH_1,1994', 'AH_1,2003', 'AH_1,2009', 'AH_1,2017', 'AH_1,2020', 'AH_1,2023', 'AH_1,2030', 'AH_1,2034', 'AH_1,2036', 'AH_1,2047', 'AH_1,2050', 'AH_1,2071', 'AH_1,2081', 'AH_1,2086', 'AH_1,2087', 'AH_1,2097', 'AH_1,2108', 'AH_1,2120', 'AH_1,2133', 'AH_1,2135', 'AH_1,2140', 'AH_1,2146', 'AH_1,2160', 'AH_1,2166', 'AH_1,2178', 'AH_1,2208', 'AH_1,2217', 'AH_1,2224', 'AH_1,2226', 'AH_1,2234', 'AH_1,2243', 'AH_1,2259', 'AH_1,2269', 'AH_1,2289', 'AH_1,2297', 'AH_1,2307', 'AH_1,2317', 'AH_1,2320', 'AH_1,2342', 'AH_1,2374', 'AH_1,2398', 'AH_1,2405', 'AH_1,2413', 'AH_1,2418', 'AH_1,2436', 'AH_1,2441', 'AH_1,2442', 'AH_1,2450', 'AH_1,2458', 'AH_1,2461', 'AH_1,2507', 'AH_1,2516', 'AH_1,2523', 'AH_1,2528', 'AH_1,2540', 'AH_1,2541', 'AH_1,2544', 'AH_1,2566', 'AH_1,2575', 'AH_1,2585', 'AH_1,2589', 'AH_1,2594', 'AH_1,2610', 'AH_1,2619', 'AH_1,2642', 'AH_1,2643', 'AH_1,2646', 'AH_1,2650', 'AH_1,2654', 'AH_1,2658', 'AH_1,2664', 'AH_1,2665', 'AH_1,2679', 'AH_1,2694', 'AH_1,2712', 'AH_1,2718', 'AH_1,2722', 'AH_1,2727', 'AH_1,2736', 'AH_1,2737', 'AH_1,2750', 'AH_1,2753', 'AH_1,2756', 'AH_1,2767', 'AH_1,2770', 'AH_1,2772', 'AH_1,2776', 'AH_1,2781', 'AH_1,2784', 'AH_1,2793', 'AH_1,2809', 'AH_1,2811', 'AH_1,2820', 'AH_1,2823', 'AH_1,2847', 'AH_1,2854', 'AH_1,2872', 'AH_1,2876', 'AH_1,2906', 'AH_1,2910', 'AH_1,2955', 'AH_1,2966', 'AH_1,2973', 'AH_1,2980', 'AH_1,2987', 'AH_1,3008', 'AH_1,3026', 'AH_1,3055', 'AH_1,3061', 'AH_1,3073', 'AH_1,3076', 'AH_1,3082', 'AH_1,3088', 'AH_1,3095', 'AH_1,3101', 'AH_1,3102', 'AH_1,3106', 'AH_1,3120', 'AH_1,3125', 'AH_1,3126', 'AH_1,3130', 'AH_1,3147', 'AH_1,3150', 'AH_1,3151', 'AH_1,3176', 'AH_1,3181', 'AH_1,3196', 'AH_1,3197', 'AH_1,3202', 'AH_1,3205', 'AH_1,3220', 'AH_1,3243', 'AH_1,3249', 'AH_1,3268', 'AH_1,3272', 'AH_1,3277', 'AH_1,3284', 'AH_1,3296', 'AH_1,3312', 'AH_1,3313', 'AH_1,3322', 'AH_1,3323', 'AH_1,3324', 'AH_1,3342', 'AH_1,3343', 'AH_1,3353', 'AH_1,3361', 'AH_1,3377', 'AH_1,3392', 'AH_1,3393', 'AH_1,3409', 'AH_1,3413', 'AH_1,3420', 'AH_1,3424', 'AH_1,3430', 'AH_1,3445', 'AH_1,3449', 'AH_1,3464', 'AH_1,3469', 'AH_1,3476', 'AH_1,3477', 'AH_1,3488', 'AH_1,3496', 'AH_1,3503', 'AH_1,3513', 'AH_1,3514', 'AH_1,3539', 'AH_1,3542', 'AH_1,3543', 'AH_1,3556', 'AH_1,3558', 'AH_1,3565', 'AH_1,3566', 'AH_1,3580', 'AH_1,3583', 'AH_1,3586', 'AH_1,3591', 'AH_1,3601', 'AH_1,3605', 'AH_1,3607', 'AH_1,3628', 'AH_1,3637', 'AH_1,3670', 'AH_1,3682', 'AH_1,3686', 'AH_1,3693', 'AH_1,3699', 'AH_1,3701', 'AH_1,3707', 'AH_1,3720', 'AH_1,3735', 'AH_1,3743', 'AH_1,3761', 'AH_1,3762', 'AH_1,3767', 'AH_1,3793', 'AH_1,3795', 'AH_1,3796', 'AH_1,3810', 'AH_1,3820', 'AH_1,3834', 'AH_1,3836', 'AH_1,3852', 'AH_1,3859', 'AH_1,3863', 'AH_1,3873', 'AH_1,3874', 'AH_1,3881', 'AH_1,3886', 'AH_1,3889', 'AH_1,3902', 'AH_1,3908', 'AH_1,3915', 'AH_1,3920', 'AH_1,3930', 'AH_1,3940', 'AH_1,3977', 'AH_1,4015', 'AH_1,4037', 'AH_1,4041', 'AH_1,4042', 'AH_1,4044', 'AH_1,4047', 'AH_1,4049', 'AH_1,4057', 'AH_1,4069', 'AH_1,4083', 'AH_1,4087', 'AH_1,4091', 'AH_1,4095', 'AH_1,4098', 'AH_1,4099', 'AH_1,4114', 'AH_1,4120', 'AH_1,4128', 'AH_1,4139', 'AH_1,4160', 'AH_1,4206', 'AH_1,4229', 'AH_1,4251', 'AH_1,4257', 'AH_1,4270', 'AH_1,4294', 'AH_1,4301', 'AH_1,4310', 'AH_1,4313', 'AH_1,4347', 'AH_1,4372', 'AH_1,4373', 'AH_1,4405', 'AH_1,4412', 'AH_1,4417', 'AH_1,4423', 'AH_1,4424', 'AH_1,4426', 'AH_1,4428', 'AH_1,4476', 'AH_1,4478', 'AH_1,4492', 'AH_1,4496', 'AH_1,4502', 'AH_1,4542', 'AH_1,4552', 'AH_1,4580', 'AH_1,4582', 'AH_1,4585', 'AH_1,4596', 'AH_1,4597', 'AH_1,4602', 'AH_1,4603', 'AH_1,4611', 'AH_1,4616', 'AH_1,4618', 'AH_1,4620', 'AH_1,4622', 'AH_1,4626', 'AH_1,4634', 'AH_1,4640', 'AH_1,4649', 'AH_1,4668', 'AH_1,4679', 'AH_1,4681', 'AH_1,4689', 'AH_1,4691', 'AH_1,4706', 'AH_1,4711', 'AH_1,4720', 'AH_1,4731', 'AH_1,4733', 'AH_1,4737', 'AH_1,4756', 'AH_1,4764', 'AH_1,4782', 'AH_1,4802', 'AH_1,4805', 'AH_1,4819', 'AH_1,4835', 'AH_1,4837', 'AH_1,4855', 'AH_1,4857', 'AH_1,4864', 'AH_1,4874', 'AH_1,4886', 'AH_1,4892', 'AH_1,4898', 'AH_1,4905', 'AH_1,4906', 'AH_1,4918', 'AH_1,4919', 'AH_1,4923', 'AH_1,4927', 'AH_1,4939', 'AH_1,4949', 'AH_1,4958', 'AH_1,4959', 'AH_1,4969', 'AH_1,4999', 'AH_1,5011', 'AH_1,5015', 'AH_1,5018', 'AH_1,5023', 'AH_1,5036', 'AH_1,5038', 'AH_1,5043', 'AH_1,5044', 'AH_1,5048', 'AH_1,5064', 'AH_1,5066', 'AH_1,5071', 'AH_1,5079', 'AH_1,5086', 'AH_1,5097', 'AH_1,5104', 'AH_1,5108', 'AH_1,5120', 'AH_1,5128', 'AH_1,5129', 'AH_1,5135', 'AH_1,5144', 'AH_1,5145', 'AH_1,5153', 'AH_1,5159', 'AH_1,5165', 'AH_1,5170', 'AH_1,5180', 'AH_1,5182', 'AH_1,5191', 'AH_1,5218', 'AH_1,5222', 'AH_1,5251', 'AH_1,5253', 'AH_1,5255', 'AH_1,5277', 'AH_1,5278', 'AH_1,5290', 'AH_1,5295', 'AH_1,5308', 'AH_1,5310', 'AH_1,5314', 'AH_1,5331', 'AH_1,5344', 'AH_1,5357', 'AH_1,5384', 'AH_1,5401', 'AH_1,5425', 'AH_1,5460', 'AH_1,5461', 'AH_1,5467', 'AH_1,5490', 'AH_1,5496', 'AH_1,5508', 'AH_1,5521', 'AH_1,5538', 'AH_1,5540', 'AH_1,5544', 'AH_1,5546', 'AH_1,5547', 'AH_1,5553', 'AH_1,5557', 'AH_1,5573', 'AH_1,5594', 'AH_1,5596', 'AH_1,5627', 'AH_1,5635', 'AH_1,5637', 'AH_1,5638', 'AH_1,5645', 'AH_1,5654', 'AH_1,5662', 'AH_1,5664', 'AH_1,5675', 'AH_1,5692', 'AH_1,5704', 'AH_1,5728', 'AH_1,5731', 'AH_1,5735', 'AH_1,5737', 'AH_1,5746', 'AH_1,5770', 'AH_1,5775', 'AH_1,5785', 'AH_1,5794', 'AH_1,5799', 'AH_1,5832', 'AH_1,5833', 'AH_1,5859', 'AH_1,5889', 'AH_1,5891', 'AH_1,5898', 'AH_1,5901', 'AH_1,5902', 'AH_1,5925', 'AH_1,5936', 'AH_1,5944', 'AH_1,5956', 'AH_1,5963', 'AH_1,5967', 'AH_1,5992', 'AH_1,5993', 'AH_1,6006', 'AH_1,6009', 'AH_1,6014', 'AH_1,6015', 'AH_1,6053', 'AH_1,6066', 'AH_1,6093', 'AH_1,6109', 'AH_1,6158', 'AH_1,6162', 'AH_1,6165', 'AH_1,6190', 'AH_1,6192', 'AH_1,6217', 'AH_1,6224', 'AH_1,6255', 'AH_1,6266', 'AH_1,6269', 'AH_1,6275', 'AH_1,6287', 'AH_1,6293', 'AH_1,6312', 'AH_1,6324', 'AH_1,6329', 'AH_1,6340', 'AH_1,6391', 'AH_1,6417', 'AH_1,6424', 'AH_1,6436', 'AH_1,6452', 'AH_1,6461', 'AH_1,6489', 'AH_1,6498', 'AH_1,6510', 'AH_1,6514', 'AH_1,6515', 'AH_1,6527', 'AH_1,6539', 'AH_1,6568', 'AH_1,6577', 'AH_1,6592', 'AH_1,6595', 'AH_1,6616', 'AH_1,6626', 'AH_1,6635', 'AH_1,6642', 'AH_1,6652', 'AH_1,6654', 'AH_1,6659', 'AH_1,6668', 'AH_1,6675', 'AH_1,6681', 'AH_1,6684', 'AH_1,6695', 'AH_1,6708', 'AH_1,6719', 'AH_1,6753', 'AH_1,6754', 'AH_1,6762', 'AH_1,6765', 'AH_1,6770', 'AH_1,6774', 'AH_1,6848', 'AH_1,6865', 'AH_1,6873', 'AH_1,6874', 'AH_1,6878', 'AH_1,6883', 'AH_1,6890', 'AH_1,6917', 'AH_1,6965', 'AH_1,6980', 'AH_1,6992', 'AH_1,7004', 'AH_1,7046', 'AH_1,7054', 'AH_1,7055', 'AH_1,7057', 'AH_1,7099', 'AH_1,7101', 'AH_1,7114', 'AH_1,7130', 'AH_1,7141', 'AH_1,7146', 'AH_1,7148', 'AH_1,7150', 'AH_1,7167', 'AH_1,7172', 'AH_1,7190', 'AH_1,7216', 'AH_1,7228', 'AH_1,7261', 'AH_1,7271', 'AH_1,7272', 'AH_1,7275', 'AH_1,7324', 'AH_1,7330', 'AH_1,7394', 'AH_1,7405', 'AH_1,7414', 'AH_1,7415', 'AH_1,7416', 'AH_1,7421', 'AH_1,7428', 'AH_1,7442', 'AH_1,7468', 'AH_1,7472', 'AH_1,7474', 'AH_1,7478', 'AH_1,7483', 'AH_1,7508', 'AH_1,7510', 'AH_1,7538', 'AH_1,7562', 'AH_1,7655', 'AH_1,7671', 'AH_1,7684', 'AH_1,7693', 'AH_1,7729', 'AH_1,7752', 'AH_1,7788', 'AH_1,7810', 'AH_1,7851', 'AH_1,7870', 'AH_1,7877', 'AH_1,7881', 'AH_1,7884', 'AH_1,7895', 'AH_1,7898', 'AH_1,7900', 'AH_1,7953', 'AH_1,7981', 'AH_1,7987', 'AH_1,8007', 'AH_1,8022', 'AH_1,8144', 'AH_1,8147', 'AH_1,8148', 'AH_1,8173', 'AH_1,8229', 'AH_1,8253', 'AH_1,8272', 'AH_1,8287', 'AH_1,8370', 'AH_1,8371', 'AH_1,8377', 'AH_1,8381', 'AH_1,8410', 'AH_1,8468', 'AH_1,8536', 'AH_1,8572', 'AH_1,8607', 'AH_1,8664', 'AH_1,8678', 'AH_1,8683', 'AH_1,8707', 'AH_1,8761', 'AH_1,8764', 'AH_1,8797', 'AH_1,8828', 'AH_1,8856', 'AH_1,8929', 'AH_1,8999', 'AH_1,9027', 'AH_1,9045', 'AH_1,9055', 'AH_1,9067', 'AH_1,9076', 'AH_1,9079', 'AH_1,9112', 'AH_1,9138', 'AH_1,9193', 'AH_1,9218', 'AH_1,9230', 'AH_1,9267', 'AH_1,9329', 'AH_1,9396', 'AH_1,9398', 'AH_1,9604', 'AH_1,9612', 'AH_1,9620', 'AH_1,9669', 'AH_1,9705', 'AH_1,9733', 'AH_1,9804', 'AH_1,9827', 'AH_1,9841', 'AH_2,0022', 'AH_2,0034', 'AH_2,0036', 'AH_2,0042', 'AH_2,0181', 'AH_2,0184', 'AH_2,0190', 'AH_2,0224', 'AH_2,0236', 'AH_2,0290', 'AH_2,0511', 'AH_2,0566', 'AH_2,0929', 'AH_2,0931', 'AH_2,0977', 'AH_2,0997', 'AH_2,1005', 'AH_2,1010', 'AH_2,1074', 'AH_2,1107', 'AH_2,1395', 'AH_2,1719', 'AH_2,1806']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation\n",
        "grouped_feature_ls = []\n",
        "correlated_groups = []\n",
        "\n",
        "def correlation(dataset, threshold):\n",
        "    col_corr = set()\n",
        "    numeric_df = dataset.select_dtypes(include=['number'])  # Only numeric columns\n",
        "    col_matrix = numeric_df.corr()\n",
        "    for i in range(len(col_matrix.columns)):\n",
        "        for j in range(i):\n",
        "            if abs(col_matrix.iloc[i, j]) > threshold:\n",
        "                colname = col_matrix.columns[i]\n",
        "                col_corr.add(colname)\n",
        "    return col_corr\n",
        "\n",
        "corr_features = correlation(df, 0.9)\n",
        "corr_final = set(corr_features)\n",
        "print(len(corr_final))\n",
        "\n"
      ],
      "metadata": {
        "id": "mH26mEAHcRRn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#quasi-constant features\n",
        "X = df2.drop('CO(GT)', axis=1)\n",
        "y = df2['CO(GT)']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
        "quasi_constant_features=[]\n",
        "quasi_constant_features = []\n",
        "for feature in X_train.columns:\n",
        "    if X_train[feature].dropna().empty:\n",
        "        continue\n",
        "    predominant = (\n",
        "        X_train[feature].value_counts(normalize=True, dropna=False)\n",
        "        .sort_values(ascending=False)\n",
        "        .values[0]\n",
        "    )\n",
        "    if predominant > 0.99:\n",
        "        quasi_constant_features.append(feature)\n",
        "\n",
        "print(len(quasi_constant_features))\n",
        "print(quasi_constant_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-IC6VoiIegLx",
        "outputId": "b5042451-eb98-4839-d957-756cc7c002cc"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#duplicated features\n",
        "dup=[]\n",
        "for i in range(0,len(X_train.columns)):\n",
        "  col1=X_train.columns[i]\n",
        "  for col2 in X_train.columns[i+1:]:\n",
        "    if(X_train[col1].equals(X_train[col2])):\n",
        "      dup.append(col2)\n",
        "print(len(dup))\n",
        "print(dup)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CiyNGWsnfSD1",
        "outputId": "58878159-6e2b-40e5-96d6-4c785dd46fd1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "['Unnamed: 16']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation\n",
        "grouped_feature_ls = []\n",
        "correlated_groups = []\n",
        "\n",
        "def correlation(dataset, threshold):\n",
        "    col_corr = set()\n",
        "    numeric_df = dataset.select_dtypes(include=['number'])  # Only numeric columns\n",
        "    col_matrix = numeric_df.corr()\n",
        "    for i in range(len(col_matrix.columns)):\n",
        "        for j in range(i):\n",
        "            if abs(col_matrix.iloc[i, j]) > threshold:\n",
        "                colname = col_matrix.columns[i]\n",
        "                col_corr.add(colname)\n",
        "    return col_corr\n",
        "\n",
        "corr_features = correlation(df2, 0.9)\n",
        "corr_final = set(corr_features)\n",
        "print(len(corr_final))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECoHntQsfXtN",
        "outputId": "9be555e5-b635-4d2a-bc94-3a53312a35e9"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_selection import mutual_info_regression, SelectKBest\n",
        "from sklearn.model_selection import train_test_split\n",
        "df2 = df2.dropna()\n",
        "\n",
        "X = df2.drop('CO(GT)', axis=1)\n",
        "y = df2['CO(GT)']\n",
        "\n",
        "X = pd.get_dummies(X, drop_first=True)\n",
        "\n",
        "X = X.fillna(0)\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=0\n",
        ")\n",
        "\n",
        "mi_scores = mutual_info_regression(X_train, y_train)\n",
        "mi_scores = pd.Series(mi_scores, index=X_train.columns)\n",
        "mi_scores = mi_scores.sort_values(ascending=False)\n",
        "\n",
        "\n",
        "print(mi_scores.head(10))\n",
        "\n",
        "selector = SelectKBest(score_func=mutual_info_regression, k=10)\n",
        "selector.fit(X_train, y_train)\n",
        "top_features = X_train.columns[selector.get_support()]\n",
        "print( top_features.tolist())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMB1RorZolYD",
        "outputId": "11cfe9c3-a9ee-4128-da8b-88963be10b0b"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top MI scores:\n",
            " G2             1.233813\n",
            "G1             0.788002\n",
            "failures       0.123197\n",
            "Pstatus_T      0.122901\n",
            "absences       0.108814\n",
            "Fjob_other     0.102436\n",
            "nursery_yes    0.095343\n",
            "address_U      0.092662\n",
            "higher_yes     0.088003\n",
            "studytime      0.080002\n",
            "dtype: float64\n",
            "Top 10 selected features:\n",
            " Index(['age', 'Medu', 'failures', 'Dalc', 'health', 'G1', 'G2',\n",
            "       'guardian_mother', 'activities_yes', 'higher_yes'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    }
  ]
}